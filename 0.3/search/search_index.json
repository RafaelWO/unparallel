{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Unparallel","text":"<p>Create async HTTP requests with Python in no time.</p> <p> </p> <p>With Unparallel you can easily create thousands of web requests in an efficient way leveraging Python's async capabilities.</p> <p>Unparallel is built on top of HTTPX and aims to support its rich set of features.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install unparallel\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>A simple example of doing several GET requests to an HTTP web service:</p> <pre><code>import asyncio\n\nfrom unparallel import up\n\n\nasync def main():\n    urls = [f\"https://httpbin.org/get?i={i}\" for i in range(5)]\n    results = await up(urls)\n    print([item[\"args\"] for item in results])\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>This prints: <pre><code>Making async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00,  9.98it/s]\n[{'i': '0'}, {'i': '1'}, {'i': '2'}, {'i': '3'}, {'i': '4'}]\n</code></pre></p> <p>Similarly, we can do a bunch of POST requests. This time we will use a single path but multiple payloads:</p> <pre><code>import asyncio\n\nfrom unparallel import up\n\n\nasync def main():\n    url = \"https://httpbin.org/post\"\n    payloads = [{\"obj_id\": i} for i in range(5)]\n    results = await up(url, method=\"post\", payloads=payloads)\n    print([item[\"data\"] for item in results])\n\n\nasyncio.run(main())\n</code></pre> <p>This prints: <pre><code>Making async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00,  9.98it/s]\n['{\"obj_id\": 0}', '{\"obj_id\": 1}', '{\"obj_id\": 2}', '{\"obj_id\": 3}', '{\"obj_id\": 4}']\n</code></pre></p> <p>For more details on the usage and examples, check out the docs.</p>"},{"location":"#why-unparallel-why-async","title":"Why unparallel? Why async?","text":"<p>Async is a really powerful feature - especially when you have to wait for I/O. Here is an example of making 20 web requests synchronously vs. asynchronously via <code>unparallel</code>.</p> <p></p> <p>As you can see, the async version finishes in less than a second.</p> Code for sync <pre><code>import httpx\nfrom tqdm import tqdm\n\n\ndef main():\n    url = \"https://httpbin.org\"\n    paths = [f\"/get?i={i}\" for i in range(20)]\n    results = [\n        httpx.get(f\"{url}{path}\") for path in tqdm(paths, desc=\"Making sync requests\")\n    ]\n    assert len(results) == 20\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> Code for async <pre><code>import asyncio\n\nfrom unparallel import up\n\n\nasync def main():\n    url = \"https://httpbin.org\"\n    paths = [f\"/get?i={i}\" for i in range(20)]\n\n    results = await up(paths, base_url=url)\n\n    assert len(results) == 20\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>As this project is still in early development, I'm happy for any feedback and contributions! Please refer to the contributing guidelines for details.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the <code>MIT</code> license. See LICENSE for more details.</p>"},{"location":"#credits","title":"Credits","text":"<p>This project was heavily inspired by the blog post Making 1 million requests with python-aiohttp by Pawe\u0142 Miech.</p> <p>I created this project with python-package-template.</p>"},{"location":"contributing/","title":"How to contribute","text":""},{"location":"contributing/#dependencies","title":"Dependencies","text":"<p>We use <code>poetry</code> to manage the dependencies. If you dont have <code>poetry</code>, you should install with <code>make poetry-download</code>.</p> <p>To install dependencies and prepare <code>pre-commit</code> hooks you would need to run <code>install</code> command:</p> <pre><code>make install\nmake pre-commit-install\n</code></pre> <p>To activate your <code>virtualenv</code> run <code>poetry shell</code>.</p>"},{"location":"contributing/#codestyle","title":"Codestyle","text":"<p>After installation you may execute code formatting.</p> <pre><code>make codestyle\n</code></pre>"},{"location":"contributing/#checks","title":"Checks","text":"<p>Many checks are configured for this project. Command <code>make check-codestyle</code> will check black and isort. The <code>make check-typing</code> command will run mypy to check for typing issues. </p> <p>Comand <code>make lint</code> applies both checks above.</p> <p>The <code>make check-safety</code> command will look at the security of your code. </p>"},{"location":"contributing/#before-submitting","title":"Before submitting","text":"<p>Before submitting your code please do the following steps:</p> <ol> <li>Add any changes you want</li> <li>Add tests for the new changes</li> <li>Edit documentation if you have changed something significant</li> <li>Run <code>make codestyle</code> to format your changes.</li> <li>Run <code>make lint</code> to ensure that types, security and docstrings are okay.</li> </ol>"},{"location":"contributing/#other-help","title":"Other help","text":"<p>You can contribute by spreading a word about this library. It would also be a huge contribution to write a short article on how you are using this project. You can also share your best practices with us.</p>"},{"location":"contributing/#makefile-reference","title":"Makefile reference","text":"<p><code>Makefile</code> contains a lot of functions for faster development.</p> 1. Download and remove Poetry <p>  To download and install Poetry run:  <pre><code>make poetry-download\n</code></pre>  To uninstall  <pre><code>make poetry-remove\n</code></pre> </p> 2. Install all dependencies and pre-commit hooks <p>  Install requirements:  <pre><code>make install\n</code></pre>  Pre-commit hooks coulb be installed after `git init` via  <pre><code>make pre-commit-install\n</code></pre> </p> 3. Codestyle <p>  Automatic formatting uses `pyupgrade`, `isort` and `black`.  <pre><code>make codestyle\n\n# or use synonym\nmake formatting\n</code></pre>  Codestyle checks only, without rewriting files:  <pre><code>make check-codestyle\n</code></pre>  &gt; Note: `check-codestyle` uses `isort` and `black` library   4. Code security <p> <pre><code>make check-safety\n</code></pre>  This command launches `Poetry` integrity checks as well as identifies security issues with `Safety` and `Bandit`.  <pre><code>make check-safety\n</code></pre> </p> </p> 5. Type checks <p>  Run `mypy` static type checker  <pre><code>make check-typing\n</code></pre> </p> 6. Tests with coverage badges <p>  Run `pytest`  <pre><code>make test\n</code></pre> </p> 7. All linters <p>  Of course there is a command to run all linters in one:  <pre><code>make lint\n</code></pre>  the same as:  <pre><code>make check-codestyle &amp;&amp; make check-typing\n</code></pre> </p> 8. Docker <p> <pre><code>make docker-build\n</code></pre>  which is equivalent to:  <pre><code>make docker-build VERSION=latest\n</code></pre>  Remove docker image with  <pre><code>make docker-remove\n</code></pre>  More information [about docker](https://github.com/RafaelWO/unparallel/tree/main/docker).  </p> 9. Cleanup <p> Delete pycache files  <pre><code>make pycache-remove\n</code></pre>  Remove package build  <pre><code>make build-remove\n</code></pre>  Delete .DS_STORE files  <pre><code>make dsstore-remove\n</code></pre>  Remove .mypycache  <pre><code>make mypycache-remove\n</code></pre>  Or to remove all above run:  <pre><code>make cleanup\n</code></pre> </p>"},{"location":"examples/","title":"Examples","text":"<p>This page contains some more advanced and realistic examples of using Unparallel.</p>"},{"location":"examples/#query-all-posts-of-a-wordpress-site","title":"Query (all) posts of a WordPress site","text":"<pre><code>\"\"\"\nThis script uses the WordPress API to query (all) posts of the website\nhttps://techcrunch.com\n\nSee Also:\n    https://developer.wordpress.org/rest-api/reference/posts/\n\"\"\"\n\nimport asyncio\nfrom pprint import pp\n\nimport httpx\n\nfrom unparallel import up\nfrom unparallel.unparallel import RequestError\n\n\nasync def main():\n    page_size = 20\n    base_url = \"https://techcrunch.com/wp-json/wp/v2\"\n    pagination_url = f\"/posts?per_page={page_size}\"\n\n    # Get page count\n    page_size = 20\n    response = httpx.head(base_url + pagination_url)\n    total_pages = int(response.headers[\"X-WP-TotalPages\"])\n    print(f\"Website '{base_url}' has {total_pages} pages (page size = {page_size})\")\n\n    # Comment the line below to get all pages. Note that you might have to adjust\n    # the settings for this to work without errors. For me, it worked using\n    # max_connections=800 and timeout=60.\n\n    total_pages = min(total_pages, 500)\n\n    # Get all pages and flatten the result\n    paths = [f\"{pagination_url}&amp;page={i}\" for i in range(1, total_pages + 1)]\n    results = await up(paths, method=\"GET\", base_url=base_url, flatten_result=True)\n\n    # Check if some requests failed\n    valid_results = [item for item in results if not isinstance(item, RequestError)]\n    fails = len(results) - len(valid_results)\n    print(f\"{fails=} ({fails/len(results):.2%})\")\n\n    # Display some properties of the first 5 posts\n    intersting_keys = [\"id\", \"date\", \"slug\", \"title\", \"author\"]\n    pp(\n        [\n            {k: v for k, v in item.items() if k in intersting_keys}\n            for item in valid_results[:5]\n        ]\n    )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>If you run the example, it should print something like the following: <pre><code>Website 'https://techcrunch.com/wp-json/wp/v2' has 12202 pages (page size = 20)\nMaking async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:13&lt;00:00, 74.30it/s]\n[{'id': 2642913,\n  'date': '2023-12-26T07:05:21',\n  'slug': 'vcs-are-entering-2024-with-healthy-paranoia',\n  'title': {'rendered': 'VCs are entering 2024 with &amp;#8216;healthy '\n                        'paranoia&amp;#8217;'},\n  'author': 428363},\n {'id': 2645233,\n  'date': '2023-12-26T06:35:00',\n  'slug': 'what-vcs-are-looking-for-in-the-next-wave-of-cybersecurity-startups',\n  'title': {'rendered': 'What VCs are looking for in the next wave of '\n                        'cybersecurity startups'},\n  'author': 133574551},\n {'id': 2641499,\n  'date': '2023-12-26T06:05:55',\n  'slug': 'hackers-stole-2-billion-in-crypto-in-2023-data-shows',\n  'title': {'rendered': 'Hackers stole $2 billion in crypto in 2023, data '\n                        'shows'},\n  'author': 133574594},\n {'id': 2635851,\n  'date': '2023-12-26T05:05:28',\n  'slug': 'the-eternal-struggle-between-open-source-and-proprietary-software',\n  'title': {'rendered': 'The eternal struggle between open source and '\n                        'proprietary software'},\n  'author': 133574560},\n {'id': 2645355,\n  'date': '2023-12-26T03:52:55',\n  'slug': 'nonprofit-code-org-sues-byjus-unit-whitehat-jr-over-payment-dues',\n  'title': {'rendered': 'Nonprofit Code.org sues Byju&amp;#8217;s unit WhiteHat Jr '\n                        'over payment dues'},\n  'author': 133574269}]\n</code></pre></p>"},{"location":"examples/#fetch-the-content-of-multiple-websites","title":"Fetch the content of multiple websites","text":"<pre><code>\"\"\"\nThis script is based on a use case at StackOverflow and fetches the content of various\nwebpages.\n\nSee Also:\n    https://www.stackoverflow.com/a/57129241\n\"\"\"\n\nimport asyncio\n\nfrom unparallel import up\n\n# Extracted from https://en.wikipedia.org/wiki/List_of_most-visited_websites\nwebsites = \"\"\"https://www.google.com/\nhttps://www.youtube.com/\nhttps://www.facebook.com/\nhttps://www.wikipedia.org/\nhttps://www.instagram.com/\nhttps://www.reddit.com/\nhttps://www.amazon.com/\nhttps://www.duckduckgo.com/\nhttps://www.yahoo.com/\nhttps://www.tiktok.com/\nhttps://www.bing.com/\nhttps://www.yahoo.co.jp/\nhttps://www.weather.com/\nhttps://www.whatsapp.com/\nhttps://www.yandex.ru/\nhttps://www.openai.com/\nhttps://www.live.com/\nhttps://www.microsoft.com/\nhttps://www.linkedin.com/\nhttps://www.quora.com/\nhttps://www.twitch.tv/\nhttps://www.naver.com/\nhttps://www.netflix.com/\nhttps://www.office.com/\nhttps://www.vk.com/\nhttps://www.globo.com/\nhttps://www.Aliexpress.com/\nhttps://www.cnn.com/\nhttps://www.zoom.us/\nhttps://www.imdb.com/\nhttps://www.x.com/\nhttps://www.nytimes.com/\nhttps://www.espn.com/\nhttps://www.amazon.co.jp/\nhttps://www.pinterest.com/\nhttps://www.uol.com.br/\nhttps://www.ebay.com/\nhttps://www.marca.com/\nhttps://www.canva.com/\nhttps://www.spotify.com/\nhttps://www.bbc.com/\nhttps://www.paypal.com/\nhttps://www.apple.com/\"\"\"\n\n\nasync def main():\n    urls = websites.split(\"\\n\")\n\n    # Get all pages\n    results = await up(\n        urls, method=\"GET\", response_fn=lambda x: x.text, raise_for_status=False\n    )\n\n    # Print the content of the first 5 pages\n    for url, content in zip(urls, results[:5]):\n        print(url, repr(content[:100]))\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>If you run the example, it should print something like the following: <pre><code>Making async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 43/43 [00:03&lt;00:00, 11.60it/s]\nhttps://www.google.com/ '&lt;!doctype html&gt;&lt;html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"de-AT\"&gt;&lt;head&gt;&lt;meta cont'\nhttps://www.youtube.com/ '&lt;!DOCTYPE html&gt;&lt;html style=\"font-size: 10px;font-family: Roboto, Arial, sans-serif;\" lang=\"de-DE\" da'\nhttps://www.facebook.com/ '&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"de\" id=\"facebook\" class=\"no_js\"&gt;\\n&lt;head&gt;&lt;meta charset=\"utf-8\" /&gt;&lt;meta nam'\nhttps://www.wikipedia.org/ '&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\" class=\"no-js\"&gt;\\n&lt;head&gt;\\n&lt;meta charset=\"utf-8\"&gt;\\n&lt;title&gt;Wikipedia&lt;/title'\nhttps://www.instagram.com/ '&lt;!DOCTYPE html&gt;&lt;html class=\"_9dls\" lang=\"en\" dir=\"ltr\"&gt;&lt;head&gt;&lt;link data-default-icon=\"https://static'\n</code></pre></p>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#unparallel","title":"unparallel","text":""},{"location":"reference/#unparallel.RequestError","title":"unparallel.RequestError  <code>dataclass</code>","text":"<p>A dataclass wrapping an exception that was raised during a web request.</p> <p>Besides the exception itself, this contains the URL, method, and (optional) payload of the failed request.</p> Source code in <code>unparallel/unparallel.py</code> <pre><code>@dataclass\nclass RequestError:\n    \"\"\"A dataclass wrapping an exception that was raised during a web request.\n\n    Besides the exception itself, this contains the URL, method, and (optional) payload\n    of the failed request.\n    \"\"\"\n\n    url: str\n    method: str\n    payload: Optional[Any]\n    exception: Exception\n</code></pre>"},{"location":"reference/#unparallel.up","title":"unparallel.up  <code>async</code>","text":"<pre><code>up(\n    urls,\n    method=\"GET\",\n    base_url=None,\n    headers=None,\n    payloads=None,\n    response_fn=DEFAULT_JSON_FN,\n    flatten_result=False,\n    max_connections=100,\n    timeout=10,\n    max_retries_on_timeout=3,\n    raise_for_status=True,\n    limits=None,\n    timeouts=None,\n    progress=True,\n)\n</code></pre> <p>Creates async web requests to the specified URL(s) using <code>asyncio</code> and <code>httpx</code>.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>Union[str, List[str]]</code> <p>A list of URLs as the targets for the requests. If only one URL but multiple payloads are supplied, that URL is used for all requests. If a <code>base_url</code> is supplied, this can also be a list of paths (or one path).</p> required <code>method</code> <code>str</code> <p>HTTP method to use - one of <code>GET</code>, <code>OPTIONS</code>, <code>HEAD</code>, <code>POST</code>, <code>PUT</code>, <code>PATCH</code>, or <code>DELETE</code>. Defaults to <code>GET</code>.</p> <code>'GET'</code> <code>base_url</code> <code>Optional[str]</code> <p>The base URL of the target API/service. Defaults to None.</p> <code>None</code> <code>headers</code> <code>Optional[Dict[str, Any]]</code> <p>A dictionary of headers to use. Defaults to None.</p> <code>None</code> <code>payloads</code> <code>Optional[Any]</code> <p>A list of JSON payloads (dictionaries) e.g. for HTTP post requests. Used together with <code>urls</code>. If one payload but multiple URLs are supplied, that payload is used for all requests. Defaults to None.</p> <code>None</code> <code>response_fn</code> <code>Optional[Callable[[Response], Any]]</code> <p>The function (callback) to apply on every response of the HTTP requests. This can be an existing function of <code>httpx.Response</code> like <code>.json()</code> or <code>.read()</code>, or a custom function which takes the <code>httpx.Response</code> as the argument returns <code>Any</code>. If you set this to <code>None</code>, you will get the raw <code>httpx.Response</code>. Defaults to <code>httpx.Response.json</code>.</p> <code>DEFAULT_JSON_FN</code> <code>flatten_result</code> <code>bool</code> <p>If True and the response per request is a list, flatten that list of lists. This is useful when using paging. Defaults to False.</p> <code>False</code> <code>max_connections</code> <code>int</code> <p>The total number of simultaneous TCP connections. Defaults to 100. This is passed into <code>httpx.Limits</code>.</p> <code>100</code> <code>timeout</code> <code>int</code> <p>The timeout for requests in seconds. Defaults to 10. This is passed into <code>httpx.Timeout</code>.</p> <code>10</code> <code>max_retries_on_timeout</code> <code>int</code> <p>The maximum number retries if the requests fails due to a timeout (<code>httpx.TimeoutException</code>). Defauls to 3.</p> <code>3</code> <code>raise_for_status</code> <code>bool</code> <p>If True, <code>.raise_for_status()</code> is called on overy response.</p> <code>True</code> <code>limits</code> <code>Optional[Limits]</code> <p>The limits configuration for <code>httpx</code>. If specified, this overrides the <code>max_connections</code> parameter.</p> <code>None</code> <code>timeouts</code> <code>Optional[Timeout]</code> <p>The timeout configuration for <code>httpx</code>. If specified, this overrides the <code>timeout</code> parameter.</p> <code>None</code> <code>progress</code> <code>bool</code> <p>If set to True, progress bar is shown. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the HTTP method is not valid.</p> <code>ValueError</code> <p>If the number of URLs provided does not match the number of payloads (except if there is only one URL).</p> <p>Returns:</p> Type Description <code>List[Any]</code> <p>List[Any]:  A list of the response data per request in the same order as the</p> <code>List[Any]</code> <p>input (URLs/payloads).</p> Source code in <code>unparallel/unparallel.py</code> <pre><code>async def up(\n    urls: Union[str, List[str]],\n    method: str = \"GET\",\n    base_url: Optional[str] = None,\n    headers: Optional[Dict[str, Any]] = None,\n    payloads: Optional[Any] = None,\n    response_fn: Optional[Callable[[httpx.Response], Any]] = DEFAULT_JSON_FN,\n    flatten_result: bool = False,\n    max_connections: Optional[int] = 100,\n    timeout: Optional[int] = 10,\n    max_retries_on_timeout: int = 3,\n    raise_for_status: bool = True,\n    limits: Optional[httpx.Limits] = None,\n    timeouts: Optional[httpx.Timeout] = None,\n    progress: bool = True,\n) -&gt; List[Any]:\n    \"\"\"Creates async web requests to the specified URL(s) using ``asyncio``\n    and ``httpx``.\n\n    Args:\n        urls (Union[str, List[str]]): A list of URLs as the targets for the requests.\n            If only one URL but multiple payloads are supplied, that URL is used for\n            all requests.\n            If a ``base_url`` is supplied, this can also be a list of paths\n            (or one path).\n        method (str): HTTP method to use - one of ``GET``, ``OPTIONS``, ``HEAD``,\n            ``POST``, ``PUT``, ``PATCH``, or ``DELETE``. Defaults to ``GET``.\n        base_url (Optional[str]):  The base URL of the target API/service. Defaults to\n            None.\n        headers (Optional[Dict[str, Any]], optional): A dictionary of headers to use.\n            Defaults to None.\n        payloads (Optional[Any], optional): A list of JSON payloads (dictionaries) e.g.\n            for HTTP post requests. Used together with ``urls``. If one payload but\n            multiple URLs are supplied, that payload is used for all requests.\n            Defaults to None.\n        response_fn (Optional[Callable[[httpx.Response], Any]]): The function (callback)\n            to apply on every response of the HTTP requests. This can be an existing\n            function of ``httpx.Response`` like ``.json()`` or ``.read()``, or a custom\n            function which takes the ``httpx.Response`` as the argument returns ``Any``.\n            If you set this to ``None``, you will get the raw ``httpx.Response``.\n            Defaults to ``httpx.Response.json``.\n        flatten_result (bool): If True and the response per request is a list,\n            flatten that list of lists. This is useful when using paging.\n            Defaults to False.\n        max_connections (int): The total number of simultaneous TCP\n            connections. Defaults to 100. This is passed into ``httpx.Limits``.\n        timeout (int): The timeout for requests in seconds. Defaults to 10.\n            This is passed into ``httpx.Timeout``.\n        max_retries_on_timeout (int): The maximum number retries if the requests fails\n            due to a timeout (``httpx.TimeoutException``). Defauls to 3.\n        raise_for_status (bool): If True, ``.raise_for_status()`` is called on overy\n            response.\n        limits (Optional[httpx.Limits]): The limits configuration for ``httpx``.\n            If specified, this overrides the ``max_connections`` parameter.\n        timeouts (Optional[httpx.Timeout]): The timeout configuration for ``httpx``.\n            If specified, this overrides the ``timeout`` parameter.\n        progress (bool): If set to True, progress bar is shown.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the HTTP method is not valid.\n        ValueError: If the number of URLs provided does not match the number of\n            payloads (except if there is only one URL).\n\n    Returns:\n        List[Any]:  A list of the response data per request in the same order as the\n        input (URLs/payloads).\n    \"\"\"\n    # Check if method it valid\n    if method.upper() not in VALID_HTTP_METHODS:\n        raise ValueError(\n            f\"The method '{method}' is not a supported HTTP method. \"\n            f\"Supported methods: {VALID_HTTP_METHODS}\"\n        )\n\n    # Wrap single URL into list to check for alignment with payload\n    if isinstance(urls, str):\n        urls = [urls]\n\n    # Check if payloads align with URLs\n    if payloads:\n        if not isinstance(payloads, list):\n            payloads = [payloads]\n        if len(urls) == 1 and len(payloads) &gt; 1:\n            logging.info(f\"Using URL '{urls[0]}' for all {len(payloads)} payloads\")\n            urls = urls * len(payloads)\n        if len(payloads) == 1 and len(urls) &gt; 1:\n            logging.info(f\"Using payload '{payloads[0]}' for all {len(urls)} URLs\")\n            payloads = payloads * len(urls)\n        if len(urls) != len(payloads):\n            raise ValueError(\n                f\"The number of URLs does not match the number of payloads: \"\n                f\"{len(urls)} != {len(payloads)}\"\n            )\n\n    if timeouts is None:\n        timeouts = httpx.Timeout(timeout)\n    if limits is None:\n        if max_connections != DEFAULT_LIMITS.max_connections:\n            limits = httpx.Limits(max_connections=max_connections)\n            limits.max_keepalive_connections = DEFAULT_LIMITS.max_keepalive_connections\n        else:\n            limits = DEFAULT_LIMITS\n\n    return await request_urls(\n        urls=urls,\n        method=method,\n        base_url=base_url,\n        headers=headers,\n        payloads=payloads,\n        response_fn=response_fn,\n        flatten_result=flatten_result,\n        max_retries_on_timeout=max_retries_on_timeout,\n        raise_for_status=raise_for_status,\n        progress=progress,\n        limits=limits,\n        timeouts=timeouts,\n    )\n</code></pre>"},{"location":"releases/","title":"Releases","text":"<p>You can see the list of available releases on the GitHub Releases page.</p> <p>We follow Semantic Versions specification.</p> <p>We use <code>Release Drafter</code>. As pull requests are merged, a draft release is kept up-to-date listing the changes, ready to publish when you\u2019re ready. With the categories option, you can categorize pull requests in release notes using labels.</p>"},{"location":"releases/#list-of-labels-and-corresponding-titles","title":"List of labels and corresponding titles","text":"Label Title in Releases <code>enhancement</code>, <code>feature</code> \ud83d\ude80 Features <code>bug</code>, <code>refactoring</code>, <code>bugfix</code>, <code>fix</code> \ud83d\udd27 Fixes &amp; Refactoring <code>build</code>, <code>ci</code>, <code>testing</code> \ud83d\udce6 Build System &amp; CI/CD <code>breaking</code> \ud83d\udca5 Breaking Changes <code>documentation</code> \ud83d\udcdd Documentation <code>dependencies</code> \u2b06\ufe0f Dependencies updates <p>You can update it in <code>release-drafter.yml</code>.</p> <p>GitHub creates the <code>bug</code>, <code>enhancement</code>, and <code>documentation</code> labels for you. Dependabot creates the <code>dependencies</code> label. Create the remaining labels on the Issues tab of your GitHub repository, when you need them.</p>"},{"location":"usage/","title":"Usage","text":"<p>A basic use case for Unparallel could be fetching some JSON data from a REST API asynchronously. In the example below, we issue 100 GET requests with different query parameters.</p> <pre><code>import asyncio\n\nfrom unparallel import up\n\n\nasync def main():\n    url = \"https://httpbin.org\"\n    paths = [f\"/get?foo={i}\" for i in range(100)]\n    return await up(paths, base_url=url)\n\n\nresults = asyncio.run(main())\nprint([item[\"args\"] for item in results[:5]])\n</code></pre> <p>This prints: <pre><code>Making async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00, 99.94it/s]\n[{'foo': '0'}, {'foo': '1'}, {'foo': '2'}, {'foo': '3'}, {'foo': '4'}]\n</code></pre></p>"},{"location":"usage/#posting-data","title":"POSTing Data","text":""},{"location":"usage/#one-body-for-different-paths","title":"One body for different paths","text":"<p>If you want to do POST instead of GET requests, you just have to pass <code>method='POST'</code> to <code>up()</code> and add some data.</p> <pre><code>import asyncio\nfrom pprint import pp\n\nfrom unparallel import up\n\n\nasync def main():\n    url = \"https://httpbin.org\"\n    data = {\"item_id\": 1, \"type\": \"tree\"}\n    paths = [f\"/post?bar={i}\" for i in range(100)]\n    return await up(paths, method=\"POST\", base_url=url, payloads=data)\n\n\nresults = asyncio.run(main())\npp([{\"args\": item[\"args\"], \"data\": item[\"data\"]} for item in results[:5]])\n</code></pre> <p>This prints: <pre><code>Making async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00, 63.40it/s]\n[{'args': {'bar': '0'}, 'data': '{\"item_id\": 1, \"type\": \"tree\"}'},\n {'args': {'bar': '1'}, 'data': '{\"item_id\": 1, \"type\": \"tree\"}'},\n {'args': {'bar': '2'}, 'data': '{\"item_id\": 1, \"type\": \"tree\"}'},\n {'args': {'bar': '3'}, 'data': '{\"item_id\": 1, \"type\": \"tree\"}'},\n {'args': {'bar': '4'}, 'data': '{\"item_id\": 1, \"type\": \"tree\"}'}]\n</code></pre></p>"},{"location":"usage/#different-bodies-for-one-path","title":"Different bodies for one path","text":"<p>As you might not need different query parameters for your POST URL, i.e. you have only one URL/path, but you want to POST a list of different JSON bodies, this is also supported.</p> <pre><code>import asyncio\nfrom pprint import pp\n\nfrom unparallel import up\n\n\nasync def main():\n    url = \"https://httpbin.org\"\n    path = \"/post\"\n    data = [{\"type\": \"tree\", \"height\": i} for i in range(100)]\n    return await up(path, method=\"POST\", base_url=url, payloads=data)\n\n\nresults = asyncio.run(main())\npp([item[\"data\"] for item in results[:5]])\n</code></pre> <p>This prints: <pre><code>Making async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00, 63.40it/s]\n['{\"type\": \"tree\", \"height\": 0}',\n '{\"type\": \"tree\", \"height\": 1}',\n '{\"type\": \"tree\", \"height\": 2}',\n '{\"type\": \"tree\", \"height\": 3}',\n '{\"type\": \"tree\", \"height\": 4}']\n</code></pre></p>"},{"location":"usage/#custom-response-functions","title":"Custom response functions","text":"<p>Per default, Unparallel will call the <code>.json()</code> function on every <code>httpx.Response</code> and return the result. But you might want to get other data from the response like the content as plain-text or the HTTP status.</p> <p>For this, define your own response function/callback using a <code>def</code> or <code>lambda</code> and pass it to <code>up()</code> via the keyword <code>response_fn</code>. The function will receive a <code>httpx.Response</code> object as the argument and can return anything.</p> <p>If you want to process the raw <code>httpx.Response</code> later yourself, you can simply set <code>response_fn=None</code>.</p> <p>The example below demonstrates how to use a custom response function to get the <code>.text</code> of a response:</p> <pre><code>import asyncio\n\nfrom unparallel import up\n\n\nasync def main():\n    urls = [\"https://www.example.com\", \"https://duckduckgo.com/\", \"https://github.com\"]\n    return await up(urls, response_fn=lambda x: x.text)\n\n\nresults = asyncio.run(main())\nfor res in results:\n    print(repr(res[:50]))\n</code></pre> <p>This should print something similar to the following: <pre><code>Making async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00,  4.43it/s]\n'&lt;!doctype html&gt;\\n&lt;html&gt;\\n&lt;head&gt;\\n    &lt;title&gt;Example D'\n'&lt;!DOCTYPE html&gt;&lt;html lang=\"en-US\"&gt;&lt;head&gt;&lt;meta char'\n'\\n\\n\\n\\n\\n\\n&lt;!DOCTYPE html&gt;\\n&lt;html\\n  lang=\"en\"\\n  \\n  \\n  da'\n</code></pre></p>"},{"location":"usage/#other-http-methods","title":"Other HTTP methods","text":"<p>Besides the popular GET and POST methods, you can use any other HTTP method supported by HTTPX - which are <code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>DELETE</code>, <code>HEAD</code>, <code>PATCH</code>, and <code>OPTIONS</code>.</p> <p>For example, you can get the status of services/webpages using the method <code>HEAD</code> in combination with a custom response function:</p> <pre><code>import asyncio\n\nfrom unparallel import up\n\n\nasync def main():\n    urls = [\"https://www.example.com\", \"https://duckduckgo.com/\", \"https://github.com\"]\n    return await up(urls, method=\"HEAD\", response_fn=lambda x: x.status_code)\n\n\nresults = asyncio.run(main())\nprint(results)\n</code></pre> <p>This prints: <pre><code>Making async requests: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00,  4.43it/s]\n[200, 200, 200]\n</code></pre></p>"},{"location":"usage/#pagination-and-flattening","title":"Pagination and flattening","text":"<p>Another use case for Unparallel could be fetching all items from a REST API using pagination. This is useful if there are too many objects to get them all at once and you want to avoid making a single request for every item.</p> <p>Let's say you want to list 1000 items from this University Domains and Names API. This API supports pagination via the query parameters <code>offset</code> and <code>limit</code>.</p> <pre><code>import asyncio\nfrom pprint import pp\n\nfrom unparallel import up\n\n\nasync def main():\n    url = \"http://universities.hipolabs.com\"\n    paths = [f\"/search?limit=20&amp;offset={i}\" for i in range(0, 1000, 20)]\n    return await up(paths, base_url=url)\n\n\nresults = asyncio.run(main())\nprint(f\"#Results: {len(results)}\")\npp([(type(item), len(item)) for item in results[:5]])\n</code></pre> <p>This prints: <pre><code>#Results: 50\n[(&lt;class 'list'&gt;, 20),\n (&lt;class 'list'&gt;, 20),\n (&lt;class 'list'&gt;, 20),\n (&lt;class 'list'&gt;, 20),\n (&lt;class 'list'&gt;, 20)]\n</code></pre></p> <p>Because we get a page (list of items) per request, the number of objects in <code>results</code> is 50 (1000/20) and the university metadata is within a nested array structure:</p> <pre><code>[\n    [\n        {\n            \"name\": \"Kharkiv National University\",\n            \"country\": \"Ukraine\",\n            \"alpha_two_code\": \"UA\",\n            ...\n        },\n        # ... 19 more items\n    ],\n    [\n        ... # next page of 20 items\n    ],\n    ...\n]\n</code></pre> <p>But in most cases, you would want just one list of all objects (universities), i.e. a flattened array. Unparallel will flatten the data for you if you pass <code>flatten_result=True</code>.</p> <pre><code>import asyncio\nfrom pprint import pp\n\nfrom unparallel import up\n\n\nasync def main():\n    url = \"http://universities.hipolabs.com\"\n    paths = [f\"/search?limit=20&amp;offset={i}\" for i in range(0, 1000, 20)]\n    return await up(paths, base_url=url, flatten_result=True)\n\n\nresults = asyncio.run(main())\nprint(f\"#Results: {len(results)}\")\npp([(type(item), len(item)) for item in results[:5]])\npp(results[:2])\n</code></pre> <p>This prints: <pre><code>#Results: 1000\n[(&lt;class 'dict'&gt;, 6),\n (&lt;class 'dict'&gt;, 6),\n (&lt;class 'dict'&gt;, 6),\n (&lt;class 'dict'&gt;, 6),\n (&lt;class 'dict'&gt;, 6)]\n[{'name': 'Kharkiv National University',\n  'country': 'Ukraine',\n  'alpha_two_code': 'UA',\n  'domains': ['student.karazin.ua', 'karazin.ua'],\n  'web_pages': ['https://karazin.ua'],\n  'state-province': None},\n {'name': 'Universidad T\u00e9cnica Federico Santa Mar\u00eda',\n  'country': 'Chile',\n  'alpha_two_code': 'CL',\n  'domains': ['usm.cl'],\n  'web_pages': ['https://usm.cl'],\n  'state-province': None}]\n</code></pre></p>"},{"location":"usage/#configuring-limits-and-timeouts","title":"Configuring limits and timeouts","text":"<p>You can configure connection pool limits and request timeouts using the following parameters in the <code>up()</code> method:</p> <ul> <li><code>max_connections (int)</code>: The total number of simultaneous TCP connections. This is passed into <code>httpx.Limits()</code> and defaults to 100.</li> <li><code>limits (Optional[httpx.Limits])</code>: Explicitly set the HTTPX limits configuration. This overrides <code>max_connections</code>.</li> <li><code>timeout (int)</code>: The timeout for requests in seconds. This is passed into <code>httpx.Timeout()</code> and defaults to 10.</li> <li><code>timeouts (Optional[httpx.Timeout])</code>: Explicitly set the HTTPX timeout configuration. This overrides <code>timeout</code>.</li> </ul> <p>If you don't care about a detailed timeout or limits configuration, you can use <code>up()</code> without specifying any of those options:</p> <pre><code>results = await up(urls)\n</code></pre> <p>Otherwise, you can use the simplified parameters <code>max_connections</code> for setting the connection limit and/or <code>timeout</code> for setting (all) timeouts for requests:</p> <pre><code>results = await up(urls, max_connections=10, timeout=60)\n</code></pre> <p>This results in the limits config created via <code>httpx.Limits(max_connections=10, **default_values)</code> and timeout config created via <code>httpx.Timeout(60)</code></p> <p>For more fine-grained control over limits and timeouts, just specify the HTTPX configs and pass them to <code>up()</code>:</p> <pre><code>results = await up(\n    urls,\n    limits=httpx.Limits(max_connections=20, ...),\n    timeouts=httpx.Timeout(connect=5, ...)\n)\n</code></pre>"},{"location":"usage/#retries","title":"Retries","text":"<p>Per default, every HTTP request will be retried 3 times if an exception of the type <code>httpx.TimeoutException</code> is raised. You can change the behavior by passing e.g. <code>max_retries_on_timeout=5</code> to <code>up()</code> for doing 5 retries, or pass <code>0</code> for disabling them.</p>"},{"location":"usage/#progress-bar","title":"Progress bar","text":"<p>Unparallel uses tqdm to display the progress of the HTTP requests - specifically <code>tqdm.asyncio.tqdm.as_completed()</code> is used to iterate over the list of async tasks (HTTP requests).</p> <p>You can disable the progress bar by passing <code>progress=False</code> to <code>up()</code>.</p>"}]}